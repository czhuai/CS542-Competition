{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1Ej3N8LWS714tU838y7lp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwPx8tTUUaaw","executionInfo":{"status":"ok","timestamp":1681753685792,"user_tz":240,"elapsed":19478,"user":{"displayName":"Chen ZHU","userId":"01644350571762964564"}},"outputId":"5f0842f1-48c4-42b4-b7ee-2a277941e78e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.98)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQC1GAfgUMPD"},"outputs":[],"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","tokenizer = T5Tokenizer.from_pretrained('t5-small')\n","model = T5ForConditionalGeneration.from_pretrained('t5-small')\n","input_ids = tokenizer.encode(\"Hello, my dog is cute\", return_tensors=\"pt\")  # Batch size 1\n","outputs = model(input_ids=input_ids, decoder_input_ids=input_ids, labels=input_ids)\n","print(outputs)\n","loss, prediction_scores = outputs[:2]"]},{"cell_type":"code","source":["print(len(outputs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yegv5ataXY8s","executionInfo":{"status":"ok","timestamp":1681754273156,"user_tz":240,"elapsed":626,"user":{"displayName":"Chen ZHU","userId":"01644350571762964564"}},"outputId":"1352e9f8-6f92-44ed-d2ea-c3cf314edc0f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n"]}]},{"cell_type":"code","source":["print(outputs[-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zl814Kb7Xb1B","executionInfo":{"status":"ok","timestamp":1681754287308,"user_tz":240,"elapsed":214,"user":{"displayName":"Chen ZHU","userId":"01644350571762964564"}},"outputId":"0d99fb1d-dae5-402a-ba47-97754149bdef"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-0.0235,  0.0490, -0.1531,  ..., -0.1444, -0.0982, -0.0988],\n","         [ 0.2134,  0.0752, -0.2040,  ..., -0.1085, -0.1076, -0.4276],\n","         [-0.1410,  0.0597,  0.2624,  ...,  0.1803,  0.2338, -0.1288],\n","         ...,\n","         [-0.1496, -0.0140, -0.2103,  ...,  0.0344, -0.0903,  0.1334],\n","         [-0.2262,  0.0248, -0.0235,  ..., -0.1075,  0.0131,  0.0612],\n","         [ 0.2149,  0.0967, -0.0164,  ..., -0.0685,  0.1851,  0.0746]]],\n","       grad_fn=<MulBackward0>)\n"]}]},{"cell_type":"code","source":["print(outputs[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e449OhXXXqka","executionInfo":{"status":"ok","timestamp":1681754344055,"user_tz":240,"elapsed":223,"user":{"displayName":"Chen ZHU","userId":"01644350571762964564"}},"outputId":"d2fd3463-1637-4307-dacc-dedade79cf0a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor(8.5362, grad_fn=<NllLossBackward0>), tensor([[[-36.1622,  -9.2893, -14.8891,  ..., -59.4171, -59.4531, -59.4614],\n","         [-44.1845, -11.9835, -19.7194,  ..., -64.5828, -64.5996, -64.6112],\n","         [-49.4544, -14.9225, -22.5902,  ..., -75.0719, -75.2252, -75.1727],\n","         ...,\n","         [-46.7954, -13.4281, -21.5096,  ..., -73.5383, -73.8785, -73.8512],\n","         [-43.5348,  -9.1414, -17.3822,  ..., -68.2411, -68.4807, -68.4164],\n","         [-29.7607,  -3.1417, -10.7685,  ..., -47.0156, -47.1727, -47.1472]]],\n","       grad_fn=<UnsafeViewBackward0>))\n"]}]},{"cell_type":"code","source":["tokenizer = T5Tokenizer.from_pretrained('t5-small')\n","model = T5ForConditionalGeneration.from_pretrained('t5-small')\n","input_ids = tokenizer.encode(\"summarize: Hello, my dog is cute\", return_tensors=\"pt\")  # Batch size 1\n","outputs = model.generate(input_ids)\n","print(outputs)\n","ans = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOelN7LQUvVl","executionInfo":{"status":"ok","timestamp":1681756788201,"user_tz":240,"elapsed":2337,"user":{"displayName":"Chen ZHU","userId":"01644350571762964564"}},"outputId":"6221d852-5b19-48b2-a42c-19cc822a3188"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[   0,   82, 1782,   19, 5295,   11, 5295,    5,    1]])\n","my dog is cute and cute.\n"]}]}]}